{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c813399a-c45c-45a9-9ea9-481fc9cb59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Muthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Muthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        One reviewers mentioned watching Oz episode yo...\n",
      "1        A wonderful little production br br The filmin...\n",
      "2        I thought wonderful way spend time hot summer ...\n",
      "3        Basically theres family little boy Jake thinks...\n",
      "4        Petter Matteis Love Time Money visually stunni...\n",
      "                               ...                        \n",
      "49995    I thought movie right good job It wasnt creati...\n",
      "49996    Bad plot bad dialogue bad acting idiotic direc...\n",
      "49997    I Catholic taught parochial elementary schools...\n",
      "49998    Im going disagree previous comment side Maltin...\n",
      "49999    No one expects Star Trek movies high art fans ...\n",
      "Name: Preprocessed_data, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Description: Build a sentiment analysis model to classify social media posts as positive, negative, or neutral.\n",
    "Steps:\n",
    "1.Data Collection: Gather a dataset of social media posts with labeled sentiments.\n",
    "2. Text Preprocessing: Clean and preprocess the text data by removing special characters, stopwords, and performing\n",
    "tokenization.\n",
    "3. Feature Extraction: Convert the text data into numerical features using techniques like TF-IDF or word embeddings.\n",
    "4. Model Selection: Choose a suitable classification algorithm such as Naive Bayes, Support Vector Machines, or a neural\n",
    "network.\n",
    "5. Model Training: Train the selected model using the preprocessed data.\n",
    "6. Model Evaluation: Evaluate the model's performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "7. Deployment: Create a simple web interface where users can input their own text for sentiment analysis.\n",
    "Tech Stack:\n",
    ". Python\n",
    ". Natural Language Processing libraries\n",
    ". Machine Learning frameworks\n",
    "'''\n",
    "#1)\n",
    "import pandas as pd\n",
    "data=pd.read_csv('IMDB Dataset.csv')\n",
    "#2)\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Remove Special Characters and numbers\n",
    "data['review']=data['review'].apply(lambda x:re.sub(r'\\d+','',x))\n",
    "data['review']=data['review'].apply(lambda x:re.sub(r'[^\\w\\s]','',x))\n",
    "#Perform Tokenization\n",
    "data['Tokens']=data['review'].apply(word_tokenize)\n",
    "#Remove Stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "data['Tokens']=data['Tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "data['Preprocessed_data']=data['Tokens'].apply(lambda x:' '.join(x))\n",
    "print(data['Preprocessed_data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d91016-d651-4007-885e-ca473568de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103...\n",
      "2        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "4        [0.0, 0.0, 0.0, 0.0, 0.0, 0.06511788398271987,...\n",
      "                               ...                        \n",
      "49995    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "49996    [0.0, 0.0, 0.0, 0.0, 0.0, 0.1188902570665852, ...\n",
      "49997    [0.0, 0.0, 0.0, 0.1419299357157053, 0.0, 0.087...\n",
      "49998    [0.0, 0.0, 0.1665917791363702, 0.0, 0.0, 0.0, ...\n",
      "49999    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: tfidf_features, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(max_features=1000)\n",
    "tfidf_features=tfidf_vectorizer.fit_transform(data['Preprocessed_data'])\n",
    "data['tfidf_features']=list(tfidf_features.toarray())\n",
    "print(data['tfidf_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fa4981-a0a1-43e0-82ab-4dc2f0156f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.83      7411\n",
      "    positive       0.83      0.84      0.84      7589\n",
      "\n",
      "    accuracy                           0.83     15000\n",
      "   macro avg       0.83      0.83      0.83     15000\n",
      "weighted avg       0.83      0.83      0.83     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "X=np.array(data['tfidf_features'].tolist())\n",
    "Y=data['sentiment']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#5)\n",
    "nb_classifier=MultinomialNB()\n",
    "nb_classifier.fit(X_train,y_train)\n",
    "y_pred=nb_classifier.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e82e50-2c3f-44c7-9970-8aa194155ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8339333333333333\n",
      "Precison: 0.8339524319516478\n",
      "F1-Score: 0.8339173395924018\n",
      "Recall: 0.8339333333333333\n"
     ]
    }
   ],
   "source": [
    "#6)\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precison:\",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1-Score:\",f1_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963ccf4d-5418-48b9-b28f-c7a9d14a599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7)\n",
    "#Save the Model and vectorizer using Pickle\n",
    "import pickle\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(nb_classifier,f)\n",
    "with open('vectorizer.pkl','wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d77748e-e8c0-4637-a631-c40f1f7e1491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in d:\\anaconda\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: flask-ngrok in d:\\anaconda\\lib\\site-packages (0.0.25)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in d:\\anaconda\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in d:\\anaconda\\lib\\site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in d:\\anaconda\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in d:\\anaconda\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from flask-ngrok) (2.31.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->flask-ngrok) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->flask-ngrok) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->flask-ngrok) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->flask-ngrok) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install Flask flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c170869-3fab-49c7-b5ef-c14e289c37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:44] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:03:56] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:04:01] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:04:06] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:04:08] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Jun/2024 15:04:17] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Loading the Model\n",
    "with open('model.pkl','rb') as f:\n",
    "    model=pickle.load(f)\n",
    "with open('vectorizer.pkl','rb') as f:\n",
    "    vectorizer=pickle.load(f)\n",
    "#Creating a UI\n",
    "from flask import Flask,request,render_template_string\n",
    "from flask_ngrok import run_with_ngrok\n",
    "app=Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "#HTML Template as String\n",
    "template='''\n",
    "    <html>\n",
    "        <head>\n",
    "            <title>ML Prediction</title>\n",
    "            <style>\n",
    "    \n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Machine Learning Model Prediction</h1>\n",
    "            <form action='/predict' method='post'>\n",
    "                <label for=\"input_data\">Enter the Movie Review</label>\n",
    "             <textarea name=\"input_text\"></textarea>\n",
    "                <input type=\"submit\"/>\n",
    "            </form>\n",
    "            {% if prediction %}\n",
    "            <p id='ans_predict'>Predicted Result: {{ prediction }}</p>\n",
    "            {% endif %}\n",
    "        </body>\n",
    "    </html> '''\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(template,prediction=None)\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    if(request.method=='POST'):\n",
    "        data=request.form['input_text']\n",
    "        num_features=vectorizer.transform([data])\n",
    "        prediction=model.predict(num_features)[0]\n",
    "        return render_template_string(template,prediction=prediction)\n",
    "#Run the App\n",
    "from threading import Thread\n",
    "def run_app():\n",
    "    app.run()\n",
    "flask_thread=Thread(target=run_app)\n",
    "flask_thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
